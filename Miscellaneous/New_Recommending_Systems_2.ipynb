{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmSfXw1huDPP"
   },
   "source": [
    "## **Import Libraries**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wMjmX8aOtykL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import csv\n",
    "import math\n",
    "import heapq\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woTSmIewa2HY"
   },
   "source": [
    "## **Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NS1VJCAKt6Il",
    "outputId": "561bd5ee-5dc8-49be-9f7c-dc31ee0b2a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770\n",
      "['abandonment', 'abit', 'able', 'abnormal', 'abnormality', 'absolute', 'absolutely', 'abuse', 'accept', 'accident', 'accidental', 'accordingly', 'act', 'action', 'active', 'actively', 'acupuncture', 'adapt', 'adjust', 'administer', 'admirably', 'adoptive', 'adorable', 'adult', 'adventure', 'adventurous', 'affection', 'affectionate', 'affectionately', 'affirm', 'afraid', 'aggression', 'aggressive', 'aggressively', 'agile', 'agree', 'ahead', 'aid', 'aimlessly', 'air', 'alas', 'aleck', 'alert', 'alertness', 'alfa', 'alike', 'allegedly', 'allergysharpei', 'alleviate', 'alongside', 'aloof', 'alpha', 'alright', 'amazing', 'ang', 'angel', 'animal', 'answer', 'anxiety', 'anxious', 'anytime', 'apartment', 'appeal', 'appear', 'appetite', 'apply', 'appreciate', 'apprehension', 'apprehensive', 'approx', 'aptly', 'arise', 'arm', 'arrival', 'arrive', 'artist', 'ash', 'ask', 'aspirate', 'assertive', 'assessment', 'assimilate', 'assistance', 'assume', 'assurance', 'assure', 'assured', 'attack', 'attention', 'authority', 'available', 'average', 'avoid', 'avs', 'awaken', 'away', 'awesome', 'awful', 'awhile', 'babesia', 'baby', 'bachelor', 'back', 'backyard', 'bad', 'badly', 'bag', 'bail', 'balance', 'balanced', 'bald', 'bambi', 'bare', 'barely', 'barking', 'barkish', 'base', 'bashful', 'basic', 'basically', 'basis', 'bask', 'batch', 'batok', 'beach', 'bean', 'beau', 'beautiful', 'beauty', 'bed', 'befall', 'befriend', 'begin', 'behave', 'behavior', 'behaviour', 'behavioural', 'behold', 'belly', 'belove', 'bertha', 'bff', 'big', 'bind', 'bit', 'bite', 'bitey', 'blackie', 'blanket', 'bleak', 'blind', 'blindspot', 'bliss', 'bloated', 'block', 'blockage', 'bloom', 'blossom', 'blotchy', 'boarding', 'boisterous', 'bold', 'bond', 'bonding', 'bonus', 'boop', 'bored', 'bottle', 'bounce', 'boundless', 'bowel', 'bradley', 'brandon', 'brave', 'bravely', 'bravery', 'break', 'breath', 'breed', 'bribery', 'bridge', 'bright', 'brim', 'bruise', 'brush', 'bubbly', 'bucketful', 'bud', 'bug', 'bukit', 'bully', 'bumpy', 'bunch', 'bundle', 'bunk', 'burglar', 'burrow', 'bushy', 'business', 'busy', 'cage', 'calm', 'calmly', 'cameo', 'canal', 'cantonese', 'capacity', 'captain', 'capture', 'carcass', 'carefree', 'careful', 'caregiver', 'caretaker', 'caring', 'carpark', 'carrier', 'carry', 'cartoon', 'casac', 'case', 'cataract', 'catcher', 'cause', 'caution', 'cautious', 'cautiously', 'cavity', 'cemetary', 'certain', 'chain', 'challenge', 'change', 'changed', 'changi', 'channel', 'chap', 'chapter', 'character', 'charismatic', 'charm', 'charmer', 'charming', 'chase', 'cheeky', 'cheer', 'cheerful', 'chest', 'chew', 'chewie', 'chief', 'child', 'chill', 'chip', 'chirpy', 'choke', 'choose', 'chose', 'chronic', 'cilla', 'cite', 'claim', 'clamber', 'claw', 'clean', 'cleaning', 'cleanliness', 'cleanly', 'clear', 'clearly', 'clever', 'climb', 'clinic', 'closely', 'clue', 'coated', 'coaxing', 'coffee', 'collar', 'collect', 'colored', 'colour', 'comfort', 'comfortable', 'comfortably', 'comforting', 'comical', 'commercial', 'commit', 'commitment', 'committed', 'common', 'companion', 'companionship', 'company', 'compassion', 'compassionate', 'complaint', 'complete', 'completely', 'compound', 'compulsory', 'concurrently', 'condition', 'condominium', 'conducive', 'confidence', 'confident', 'confidently', 'connection', 'conscientious', 'consider', 'consist', 'consistency', 'consistent', 'consistently', 'constantly', 'constipation', 'constraint', 'contain', 'contend', 'content', 'contented', 'contently', 'control', 'cool', 'coordinate', 'cope', 'corner', 'correct', 'correction', 'correctly', 'cosy', 'couch', 'counsellor', 'countless', 'courage', 'course', 'court', 'cover', 'covid', 'cow', 'cowardly', 'crate', 'crated', 'crave', 'crawl', 'crazy', 'creamy', 'criminal', 'cripple', 'crossbreed', 'crouch', 'crucial', 'crush', 'cuddle', 'cuddlebug', 'cuddly', 'cure', 'curious', 'curiously', 'curl', 'curly', 'current', 'curveball', 'cushion', 'customer', 'cut', 'cute', 'cutie', 'cutting', 'damage', 'dame', 'dance', 'dandy', 'danger', 'dangerous', 'dare', 'darling', 'dart', 'dashy', 'dating', 'deal', 'death', 'dedicated', 'dedication', 'deep', 'defacate', 'defect', 'defend', 'defensive', 'deforest', 'dejected', 'delight', 'deliver', 'demand', 'demeanor', 'demure', 'deny', 'dependent', 'depict', 'describe', 'deserve', 'desire', 'desmond', 'destination', 'destroy', 'destructive', 'detective', 'deter', 'develop', 'development', 'dewali', 'diamond', 'die', 'different', 'difficult', 'dig', 'dirty', 'disappear', 'discharge', 'discipline', 'discomfort', 'discover', 'disease', 'dislike', 'display', 'disposition', 'dissatisfaction', 'distressed', 'distrustful', 'disturb', 'divine', 'docile', 'dock', 'doggie', 'doggo', 'doggy', 'dogs', 'dominance', 'dominant', 'door', 'dote', 'downgrading', 'drag', 'drain', 'dramatic', 'dreaded', 'dribbling', 'drink', 'drive', 'drop', 'drown', 'dude', 'dull', 'dump', 'dunk', 'dysplasia', 'eager', 'eagerness', 'early', 'earn', 'easily', 'east', 'easy', 'eat', 'eater', 'effervescent', 'effort', 'eg', 'elderly', 'elevate', 'emaciate', 'embark', 'embarrassing', 'embrace', 'emergency', 'enable', 'enchant', 'enclosure', 'encounter', 'encourage', 'encouragement', 'endanger', 'endear', 'endearing', 'endurance', 'energetic', 'energy', 'engage', 'engagement', 'enjoy', 'enquire', 'ensure', 'entangle', 'enter', 'entertaining', 'enthused', 'enthusiasm', 'enthusiast', 'enthusiastic', 'enthusiastically', 'entice', 'entire', 'entrance', 'environmental', 'episode', 'equally', 'er', 'escalate', 'escape', 'establish', 'etc', 'euthanize', 'everyday', 'evict', 'ex', 'exactly', 'examine', 'excel', 'excellent', 'exchange', 'excitable', 'excite', 'excited', 'excitedly', 'excitement', 'exciting', 'excuse', 'exercise', 'exhibit', 'exist', 'existence', 'expand', 'expect', 'expel', 'experienced', 'expert', 'expertise', 'explain', 'explore', 'expose', 'exposure', 'express', 'expression', 'expressive', 'expressway', 'extend', 'extended', 'exterior', 'extra', 'extraordinary', 'extroverte', 'exuberance', 'exuberant', 'eyebrow', 'faber', 'face', 'facebook', 'facility', 'fact', 'factory', 'fail', 'fair', 'fairly', 'fake', 'familiarise', 'famous', 'fare', 'fast', 'fatal', 'fate', 'fear', 'fearful', 'fearless', 'feature', 'fed', 'feedback', 'fellow', 'femoral', 'fence', 'fencing', 'fend', 'feral', 'fererro', 'ferociously', 'fetch', 'fever', 'fiercely', 'fight', 'figure', 'fill', 'finally', 'finance', 'fine', 'finger', 'finish', 'fire', 'firm', 'firmly', 'fish', 'fishfarm', 'fit', 'flare', 'flatten', 'flavour', 'flesh', 'flight', 'flood', 'flop', 'floppy', 'flourish', 'fluffy', 'fluid', 'fmn', 'fo', 'focus', 'foil', 'folk', 'follow', 'follower', 'food', 'fool', 'foot', 'forage', 'force', 'foreign', 'foresee', 'forest', 'forget', 'fortunately', 'fortune', 'foundation', 'founder', 'foxy', 'free', 'freedom', 'freely', 'frenzy', 'frequent', 'frequently', 'fresh', 'friendly', 'friendship', 'frightened', 'fringe', 'fruitless', 'fruity', 'fun', 'funny', 'furniture', 'furpal', 'furry', 'fuss', 'fussy', 'game', 'gang', 'gap', 'gape', 'gardener', 'gate', 'gaze', 'gel', 'gem', 'generous', 'gentle', 'gently', 'german', 'gesture', 'gets', 'getting', 'giant', 'gibsoni', 'gift', 'gleefully', 'glow', 'gnaw', 'gobble', 'gold', 'golden', 'good', 'goodness', 'goody', 'goofball', 'goofy', 'gorgeous', 'got', 'gotten', 'grab', 'grandchild', 'gravel', 'grayish', 'great', 'greatly', 'greedily', 'greedy', 'greenery', 'grid', 'grill', 'groom', 'ground', 'growling', 'guard', 'guarding', 'guess', 'guidance', 'guide', 'gum', 'habit', 'half', 'halus', 'handfeed', 'handicap', 'handling', 'handsome', 'hang', 'happen', 'happening', 'happily', 'hard', 'hardy', 'harm', 'harness', 'harsh', 'hassle', 'hate', 'haunt', 'haze', 'hbd', 'headway', 'heal', 'healthily', 'healthy', 'healty', 'hearing', 'heartily', 'heartworm', 'heavy', 'heel', 'helicopter', 'hesitant', 'hesitate', 'hesitation', 'hide', 'hiding', 'high', 'hike', 'hill', 'hold', 'hole', 'homebody', 'homeless', 'honest', 'honestly', 'hop', 'hopeful', 'hopefully', 'horn', 'horrible', 'horrid', 'horrifying', 'hose', 'hospital', 'hot', 'hour', 'housing', 'hover', 'howl', 'hug', 'huge', 'hugger', 'humane', 'hump', 'hundred', 'hunger', 'hungry', 'hunt', 'hurt', 'hydrotherapy', 'hyper', 'hypervigilance', 'idea', 'ideal', 'ideally', 'illness', 'immediately', 'immune', 'imply', 'important', 'impossible', 'impress', 'impressive', 'improvement', 'incident', 'incidentally', 'inconsistent', 'incontinence', 'incredibly', 'independent', 'individual', 'indoor', 'inexperienced', 'infect', 'infection', 'inhale', 'initiate', 'injection', 'injure', 'inner', 'inquisitive', 'insecure', 'insecurity', 'inside', 'insist', 'install', 'instance', 'instantly', 'instead', 'instinct', 'intelligent', 'intention', 'intentional', 'interact', 'interactive', 'interest', 'interested', 'interestingly', 'interpret', 'intervention', 'intestine', 'intrigue', 'introduce', 'introduction', 'introvert', 'intruder', 'investigate', 'involve', 'irresistibly', 'irresponsible', 'island', 'italian', 'jealous', 'jiak', 'jordan', 'jovial', 'joy', 'joyful', 'jump', 'jurong', 'kangaroo', 'keen', 'key', 'kick', 'kid', 'kidney', 'killer', 'kind', 'kindly', 'kio', 'kiss', 'kranji', 'labrador', 'lame', 'language', 'lap', 'large', 'largely', 'lasso', 'late', 'later', 'laughter', 'lay', 'lazy', 'lead', 'leader', 'lean', 'learner', 'learning', 'lease', 'leash', 'legged', 'length', 'lick', 'lie', 'lifespan', 'lifestyle', 'lifetime', 'lift', 'light', 'lightweight', 'likely', 'limited', 'limp', 'line', 'link', 'listen', 'little', 'lively', 'living', 'lo', 'load', 'local', 'lock', 'loiter', 'loitering', 'lone', 'long', 'loom', 'loose', 'lord', 'lose', 'lost', 'loud', 'lounge', 'lovable', 'loveable', 'lovely', 'loving', 'low', 'loyal', 'luck', 'lunge', 'machinery', 'main', 'mainly', 'maintain', 'maintainance', 'maintenance', 'makeup', 'making', 'malnourish', 'malnutritioned', 'mama', 'manageable', 'mandai', 'mandy', 'manga', 'manner', 'mannered', 'marion', 'master', 'mat', 'matted', 'matter', 'mature', 'matured', 'maybe', 'meal', 'mean', 'meaningful', 'medication', 'medicine', 'medium', 'medley', 'meek', 'megaesophagus', 'megamart', 'megastore', 'megawatt', 'mellow', 'melt', 'mend', 'mental', 'mention', 'mercylight', 'mesmerize', 'mess', 'method', 'microchippe', 'midst', 'mild', 'min', 'mind', 'minded', 'mindful', 'mini', 'miraculous', 'mission', 'misunderstood', 'mo', 'mode', 'mom', 'moment', 'mongrel', 'monitoring', 'mood', 'morsel', 'motivate', 'motivated', 'mouthy', 'move', 'mr', 'mrsa', 'mrt', 'mt', 'mth', 'mud', 'multi', 'mum', 'muslim', 'mysterious', 'nail', 'namesake', 'nap', 'narrow', 'naturally', 'nature', 'natured', 'naughty', 'navigate', 'neck', 'negative', 'neglect', 'nelly', 'nerve', 'nervous', 'neuter', 'newbie', 'newly', 'news', 'newspaper', 'nibble', 'nice', 'nicely', 'nickname', 'nipping', 'noah', 'noami', 'non', 'nonchalent', 'nonetheless', 'normal', 'normally', 'north', 'not', 'notch', 'notice', 'noticed', 'nowadays', 'ns', 'numerous', 'nurse', 'nursery', 'nurture', 'obedient', 'observant', 'observe', 'obvious', 'obviously', 'occasion', 'occasional', 'occasionally', 'occur', 'offer', 'office', 'officer', 'offspring', 'oh', 'okay', 'onward', 'operate', 'opportunity', 'opposite', 'option', 'order', 'ordinary', 'organ', 'organisation', 'orient', 'original', 'originally', 'ostectomy', 'outcast', 'outdoor', 'outdoors', 'outdoorsy', 'outgoing', 'outgrow', 'outing', 'outnumber', 'outram', 'outside', 'outward', 'overall', 'overcome', 'overdue', 'overexuberant', 'overly', 'oversized', 'overwhelmed', 'own', 'ownership', 'pace', 'pack', 'packet', 'pad', 'pain', 'painfully', 'painstakingly', 'pair', 'pal', 'pamper', 'panic', 'panjang', 'pant', 'paper', 'parent', 'park', 'parking', 'particular', 'particularly', 'partner', 'pasir', 'pass', 'passionate', 'past', 'patient', 'patiently', 'patrol', 'pause', 'pay', 'payoh', 'peace', 'peaceful', 'peek', 'peepad', 'pen', 'perceive', 'perceptive', 'perfect', 'perfectly', 'period', 'perk', 'permanent', 'permise', 'perseverance', 'persist', 'persistant', 'persistently', 'personnel', 'perspective', 'pest', 'pet', 'petite', 'petrify', 'phase', 'photo', 'physical', 'physically', 'physique', 'picky', 'pie', 'pierce', 'pin', 'pinscher', 'pit', 'pity', 'plague', 'plain', 'plan', 'plaster', 'play', 'playful', 'playfully', 'playtime', 'pleasant', 'pleased', 'pleaser', 'pleasure', 'pneumonia', 'point', 'pointy', 'poise', 'poisoning', 'politely', 'poo', 'pooch', 'poop', 'poope', 'poor', 'poorly', 'popular', 'position', 'positive', 'possess', 'possessive', 'possible', 'post', 'postive', 'posture', 'potty', 'pound', 'pour', 'power', 'prefer', 'preferable', 'pregnancy', 'pregnant', 'prepared', 'prescribe', 'prescribed', 'presence', 'presently', 'press', 'pretend', 'pretty', 'previous', 'prey', 'problem', 'process', 'professional', 'program', 'prolapse', 'prolong', 'prompt', 'promptly', 'prop', 'proper', 'prosthetic', 'protect', 'protection', 'protective', 'protector', 'proud', 'provide', 'pup', 'pupper', 'puppy', 'pure', 'put', 'puzzle', 'python', 'quality', 'quarter', 'quick', 'quickly', 'quiet', 'quieter', 'quietly', 'quirk', 'quirky', 'quizzical', 'rainy', 'raise', 'rapidly', 'rarely', 'ray', 'raze', 'react', 'reaction', 'reactive', 'read', 'ready', 'real', 'realise', 'realize', 'reappear', 'reason', 'reasonably', 'reassurance', 'reassure', 'recall', 'recent', 'reciprocate', 'recognise', 'recognize', 'recommend', 'recovery', 'rectum', 'recuperate', 'red', 'reduce', 'reflect', 'reflective', 'refuge', 'regain', 'regard', 'regret', 'regular', 'regularly', 'relax', 'relaxed', 'release', 'relieve', 'reluctant', 'remain', 'repair', 'repeat', 'reserve', 'reserved', 'resettle', 'resident', 'resilient', 'respect', 'respectively', 'responsibility', 'responsible', 'responsibly', 'responsive', 'restore', 'result', 'resume', 'retire', 'retreat', 'reveal', 'review', 'ride', 'ris', 'rise', 'risk', 'road', 'roam', 'rocco', 'roll', 'roof', 'room', 'rose', 'rosehip', 'rosy', 'rottweiler', 'rough', 'round', 'routine', 'rub', 'rubbish', 'ruckus', 'run', 'sabotage', 'sad', 'safe', 'safely', 'safety', 'sample', 'save', 'say', 'scale', 'scar', 'scare', 'scared', 'scary', 'scatter', 'scavage', 'scavenge', 'scent', 'schedule', 'scold', 'scoop', 'scramble', 'scratch', 'scream', 'scritche', 'season', 'secretly', 'secure', 'security', 'seed', 'seek', 'segregated', 'selective', 'seletar', 'self', 'selfish', 'send', 'senior', 'sense', 'sensitive', 'sensitve', 'sentence', 'separation', 'sept', 'serve', 'session', 'set', 'setting', 'settle', 'severely', 'shade', 'shadow', 'shall', 'share', 'sharp', 'shave', 'shine', 'shiny', 'shop', 'short', 'shout', 'show', 'shower', 'shredding', 'shy', 'shyness', 'sible', 'sick', 'sickness', 'sight', 'sighting', 'sign', 'signature', 'silly', 'similar', 'simple', 'simply', 'single', 'singlehandedly', 'sis', 'sit', 'situation', 'size', 'sized', 'skill', 'skinny', 'sleep', 'slender', 'slight', 'slightly', 'slinky', 'slow', 'slowly', 'small', 'smart', 'smile', 'smiley', 'smokey', 'smooch', 'smooth', 'smother', 'snap', 'snappy', 'snarl', 'sneak', 'sng', 'sniff', 'snooze', 'snout', 'snuffle', 'snuggle', 'sociable', 'social', 'socialisation', 'socialise', 'soft', 'softly', 'sole', 'solicit', 'solitary', 'solve', 'somebody', 'son', 'sosd', 'soul', 'sound', 'soundly', 'source', 'spaniel', 'spare', 'spay', 'spca', 'speak', 'special', 'specialist', 'specialized', 'speed', 'spend', 'spidey', 'spine', 'spirit', 'spirited', 'spite', 'splendid', 'split', 'spondylosis', 'spook', 'spot', 'spring', 'spunky', 'squeaky', 'squirm', 'src', 'ss', 'stable', 'staff', 'stage', 'stair', 'stairwell', 'stalk', 'stall', 'stand', 'standing', 'stare', 'startled', 'starve', 'station', 'sterilise', 'sterilization', 'sterilize', 'stick', 'stimulate', 'stoic', 'stop', 'story', 'straight', 'strange', 'strength', 'stress', 'stressful', 'stretch', 'striking', 'strikingly', 'stroke', 'stroll', 'strong', 'strongly', 'structure', 'structured', 'struggle', 'stuck', 'stunning', 'subcutaneous', 'submissive', 'substitute', 'successful', 'successfully', 'suddenly', 'suffice', 'sufficient', 'suggest', 'suited', 'sunny', 'super', 'superbly', 'supervision', 'supplement', 'support', 'suppose', 'surface', 'surprise', 'surprisingly', 'surrender', 'surrounding', 'survival', 'survive', 'survivor', 'suspect', 'suspicion', 'swallow', 'swamp', 'sweet', 'sweetest', 'sweetheart', 'sweetie', 'swim', 'swimming', 'swinge', 'swipe', 'table', 'take', 'tale', 'talk', 'tall', 'tampine', 'target', 'task', 'taste', 'tasty', 'tasy', 'teach', 'teachable', 'team', 'teenage', 'teenager', 'teethe', 'temper', 'temperament', 'temple', 'temporary', 'tendency', 'tender', 'tennis', 'term', 'terrible', 'terrified', 'terrify', 'territorial', 'territory', 'thankful', 'theirs', 'therapy', 'thick', 'thin', 'thoughtful', 'threaten', 'thrive', 'throw', 'throwback', 'tick', 'tie', 'tight', 'till', 'timer', 'timid', 'tiny', 'tip', 'tired', 'toa', 'today', 'toddler', 'tolerant', 'tolerate', 'tom', 'torrential', 'total', 'totally', 'tough', 'tow', 'track', 'tract', 'tragically', 'trailer', 'trainable', 'trainer', 'training', 'transfer', 'transform', 'trap', 'trapping', 'traumatic', 'treasure', 'tremendously', 'trial', 'trick', 'trigger', 'trim', 'trot', 'trouble', 'truck', 'true', 'truly', 'trust', 'tuas', 'tug', 'tuggish', 'tumbling', 'tune', 'tv', 'twice', 'twin', 'twirly', 'type', 'typical', 'typically', 'tyre', 'unable', 'uncertainty', 'uncomfortable', 'unconditionally', 'uncontrollable', 'uncover', 'underneath', 'underside', 'understand', 'understands', 'unfamiliar', 'unfortunate', 'unhealthy', 'uninvited', 'unique', 'unit', 'unlock', 'unpredictable', 'unsocialized', 'untreated', 'unwilling', 'upbringing', 'update', 'upfront', 'upper', 'urban', 'urge', 'urgency', 'urinary', 'urinate', 'use', 'usual', 'uti', 'utter', 'vacated', 'vaccinate', 'vaccinated', 'valiantly', 'vehicle', 'venture', 'verge', 'veterinarian', 'vicinity', 'victim', 'vision', 'visitor', 'vivacious', 'vocal', 'voice', 'vollie', 'vomit', 'vomiting', 'wag', 'wagging', 'waggy', 'waist', 'wait', 'walk', 'walking', 'wall', 'wander', 'warm', 'warn', 'warrior', 'wash', 'waste', 'water', 'wave', 'wavy', 'weak', 'wear', 'weather', 'weigh', 'weird', 'welcome', 'welfare', 'western', 'wetland', 'whilst', 'whimper', 'whine', 'whirly', 'wide', 'wiggle', 'wild', 'will', 'willed', 'willing', 'willingly', 'win', 'window', 'wing', 'winsome', 'wit', 'witness', 'wobbly', 'wonderful', 'word', 'work', 'worker', 'worksite', 'world', 'worm', 'worried', 'worry', 'wrestle', 'wrestling', 'wriggle', 'write', 'xander', 'xiaobai', 'yard', 'yes', 'yound', 'young', 'yr', 'yummy', 'zest']\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py38gpu\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('newdata_2.csv')\n",
    "# print(tfidf['Name'])\n",
    "# print(data)\n",
    "# print(data.shape)\n",
    "\n",
    "corpus = list(data['Corpus'])\n",
    "# corpus_words = vectorizer.get_feature_names()\n",
    "vectorizer1 = CountVectorizer()\n",
    "word_vec = vectorizer1.fit_transform(corpus)\n",
    "corpus_words = vectorizer1.get_feature_names()\n",
    "\n",
    "# nlp_tool = spacy.load('en_core_web_sm')\n",
    "# for text in corpus:\n",
    "#     token_sentence = nlp_tool(text.lower())\n",
    "#     print(token_sentence)\n",
    "#     for word in token_sentence:\n",
    "#         print(word)\n",
    "\n",
    "print(len(corpus_words))\n",
    "print(corpus_words)\n",
    "# print\n",
    "print('cute' in corpus_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAbhkYpIEtbq"
   },
   "source": [
    "## **Build Up the Language Processor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mYfkXLM9E3K6"
   },
   "outputs": [],
   "source": [
    "def my_preprocessing(raw_sentence):\n",
    "    nlp_tool = spacy.load('en_core_web_sm')\n",
    "    token_sentence = nlp_tool(raw_sentence.lower())\n",
    "    with open('./irrelevant_words.txt') as file:\n",
    "        irrelevantlist = [stopword.replace('\\n', '').lower() for stopword in file.readlines()]\n",
    "#     new_sentence = [word for word in token_sentence if word not in irrelevantlist]\n",
    "    \n",
    "    preprocessed_sentence = []\n",
    "    \n",
    "    for token in token_sentence:\n",
    "        if token.pos_ == \"PUNCT\" or token.is_stop == True or token.is_alpha == False or token.pos_ == \"SYM\":\n",
    "            continue\n",
    "\n",
    "        elif token.lemma_ in irrelevantlist or len(token)==1:\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            preprocessed_sentence.append(token.lemma_)\n",
    "            \n",
    "    return preprocessed_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JRjfY4ZbAWT"
   },
   "source": [
    "## Basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dogs after filterring: 11\n",
      "Index of dogs after filtering:\n",
      "[110, 160, 178, 179, 181, 205, 219, 233, 275, 296, 297]\n"
     ]
    }
   ],
   "source": [
    "# Filter the dogs according to the hard constraints (gender, age and HDB approval)\n",
    "def filter_dog(data,gender,age,hdb):\n",
    "    filtered = []\n",
    "    if hdb == 0:\n",
    "        hdb_ = [0,1]\n",
    "    else:\n",
    "        hdb_ = [1]\n",
    "    for i in range(335):\n",
    "        if data.loc[i,'Gender'] in gender:\n",
    "            if data.loc[i,'Age'] in age:\n",
    "                if data.loc[i,'HDB'] in hdb_:\n",
    "                    filtered.append(i)\n",
    "    return filtered\n",
    "\n",
    "# Test\n",
    "filtered = filter_dog(data,[1],[2],[0])\n",
    "print('Number of dogs after filterring: ' + str(len(filtered)))\n",
    "print('Index of dogs after filtering:')\n",
    "print(filtered)\n",
    "# index = []\n",
    "# for dog in filtered:\n",
    "#     index.append(dog['Index'])\n",
    "# print(index)\n",
    "\n",
    "nofilter = filter_dog(data,[0,1],[0,1,2,3],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a list of values of dogs to calculate cosine similarity\n",
    "# def make_list(dog_index,hard_constraints,tfidf,soft_constraints):\n",
    "#     value_list = []\n",
    "#     if hard_constraints == True: \n",
    "#         value_list.append(data.loc[dog_index]['Gender'])\n",
    "#         value_list.append(data.loc[dog_index]['Age'])\n",
    "#         value_list.append(data.loc[dog_index]['HDB'])\n",
    "#     if tfidf == True:\n",
    "#         for i in range(1770):\n",
    "#             value_list.append(data.loc[dog_index]['tfidf'+str(i)])\n",
    "#     if soft_constraints == True:\n",
    "#         for i in range(6):\n",
    "#             value_list.append(data.loc[dog_index]['Tag'+str(i+3)])\n",
    "# #     print(len(value_list))\n",
    "#     return value_list\n",
    "\n",
    "# dogs_value_list = []\n",
    "# for i in range(335):\n",
    "#     dogs_value_list.append(make_list(i,True,True,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(dogx,dogy,hard_constraint,soft_constraint,tfidf,user):\n",
    "    numerator = 0\n",
    "    denominator_x = 0\n",
    "    denominator_y = 0\n",
    "    if hard_constraint == True:\n",
    "        numerator += dogx['Gender'] * dogy[indexy]['Gender']\n",
    "        numerator += dogx[indexx]['Age'] * dogy[indexy]['Age']\n",
    "        numerator += dogx[indexx]['HDB'] * dogy[indexy]['HDB']\n",
    "        denominator_x += dogx[indexx]['Gender'] ** 2\n",
    "        denominator_x += dogx[indexx]['Age'] ** 2\n",
    "        denominator_x += dogx[indexx]['HDB'] ** 2\n",
    "        denominator_y += dogy[indexx]['Gender'] ** 2\n",
    "        denominator_y += dogy[indexx]['Age'] ** 2\n",
    "        denominator_y += dogy[indexx]['HDB'] ** 2\n",
    "    if soft_constraint == True:\n",
    "        for i in range(6):\n",
    "            if user == True:\n",
    "                tagix = dogx['Tag'+str(i+3)]\n",
    "                tagiy = dogy['Tag'+str(i+3)]\n",
    "                if dogx['Tag'+str(i+3)] == 0 or dogy['Tag'+str(i+3)] != 0:\n",
    "                    tagix = 0\n",
    "                    tagiy = 0\n",
    "            numerator += tagix * tagiy\n",
    "            denominator_x += tagix ** 2\n",
    "            denominator_y += tagiy ** 2\n",
    "    if tfidf == True:\n",
    "        for i in range(1770):\n",
    "            numerator += dogx['tfidf'+str(i)] * dogy['tfidf'+str(i)]\n",
    "            denominator_x += dogx['tfidf'+str(i)]**2\n",
    "            denominator_y += dogy['tfidf'+str(i)]**2\n",
    "\n",
    "    denominator_x = math.sqrt(denominator_x)\n",
    "    denominator_y = math.sqrt(denominator_y)  \n",
    "    if denominator_x*denominator_y == 0:\n",
    "        return 0\n",
    "    return (numerator/(denominator_x*denominator_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculation of cosine similarity between two dogs\n",
    "# # For the soft constraints, if the value of one certain aspect for either dog is 0, it won't be taken into calculation.\n",
    "# def cossim_dog_dog(dogx_index,dogy_index):\n",
    "#     listx = make_list(dogx_index,hard_constraints=True,tfidf=True,soft_constraints=True)\n",
    "#     listy = make_list(dogy_index,hard_constraints=True,tfidf=True,soft_constraints=True)\n",
    "#     for i in range(1773,1779):\n",
    "#         if listx[i] == 0 or listy[i] == 0:\n",
    "#             listx[i] = 0\n",
    "#             listy[i] = 0\n",
    "#     cossim = cosine_similarity(listx,listy)\n",
    "#     return cossim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculation of cosine similarity between one dog and the user's profile\n",
    "# # Used in recommendation for a new user\n",
    "# # The hard constraints are filtered before the calcularion, thus not taken into account\n",
    "# # For the soft constraints, if the value of one certain aspect for the dog is 0, \n",
    "# # or that of the user's profile is 1, it won't be taken into calculation.\n",
    "# def cossim_dog_userprofile(user,dog_index):\n",
    "#     listx = make_list(user,False,True,True)\n",
    "#     listy = make_list(dog,False,True,True)\n",
    "#     for i in range(1773-3,1779-3):\n",
    "#         if listx[i] == 1 or listy[i] == 0:\n",
    "#             listx[i] = 0\n",
    "#             listy[i] = 0\n",
    "#     cossim = cosine_similarity(listx,listy)\n",
    "#     return cossim\n",
    "\n",
    "# # Test\n",
    "# # cossim_dog_dog(data.loc[0],data.loc[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculation of cosine similarity between one dog and the user's history selection\n",
    "# # Used in recommendation for an old user after he/she has selected some dogs\n",
    "# # Only consider the descriptions of the dogs\n",
    "# def cossim_dog_userhistory(history,dog_index):\n",
    "# #     listy = make_list(dog_index,hard_constraints=False,tfidf=True,soft_constraints=False,data)\n",
    "#     listy = make_list(dog_index,False,True,False)\n",
    "#     cossim = cosine_similarity(history,listy)\n",
    "#     return cossim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on user's history data, build a user's prefernce.\n",
    "# The return is a list\n",
    "def user_history(data,dogs_index):\n",
    "    history = []\n",
    "    history.append(999)\n",
    "    history.append('History')\n",
    "    history.append(0)\n",
    "    history.append(0)\n",
    "    history.append(0)\n",
    "    history.append('courpus')\n",
    "    for i in range(6):\n",
    "        history.append(0)\n",
    "    for i in range(1770):\n",
    "        summ = 0\n",
    "        average = 0\n",
    "        for index in dogs_index:\n",
    "            summ += data.loc[index]['tfidf'+str(i)]\n",
    "        average = summ/len(dogs_index)\n",
    "        history.append(average)\n",
    "#     data.loc[335] = history\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender for old users based on the user's history prefernece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the similar dogs according to cosine similarity\n",
    "def recommend_userhistory(data,dogs_filter_index,history_index,target_num):\n",
    "    similarity = []\n",
    "    history = user_history(data,history_index)\n",
    "    data.loc[999] = history\n",
    "    print('History preference made')\n",
    "#     num = 1\n",
    "    for index in history_index:\n",
    "        if index in dogs_filter_index:\n",
    "#             print(index)\n",
    "            dogs_filter_index.remove(index)\n",
    "    for index in dogs_filter_index:\n",
    "        cos_sim = cosine_similarity(data.loc[index],data.loc[999],hard_constraint=False,soft_constraint=False,tfidf=True,user=False)\n",
    "#         print(str(num) + '/' + str(len(dogs_filter_index)) + ' : ' + str(cos_sim))\n",
    "#         num += 1\n",
    "        similarity.append(cos_sim)\n",
    "#     print(similarity)\n",
    "    max_index_ = list(map(similarity.index, heapq.nlargest(target_num,similarity)))\n",
    "    max_index = []\n",
    "    for i in range(len(max_index_)):\n",
    "        max_index.append(dogs_filter_index[max_index_[i]])\n",
    "    max_value = heapq.nlargest(target_num,similarity)\n",
    "    return [[max_index],[max_value]]\n",
    "\n",
    "def filter_dont_like(index_old,dont_like):\n",
    "    for index in dont_like:\n",
    "        if index in index_old:\n",
    "            index_old.remove(index)\n",
    "    return index_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History preference made\n",
      "[[[198, 39, 160, 96, 146, 159, 65, 186, 81, 320]], [[0.3011773531208616, 0.22443746451740343, 0.21160883484017914, 0.20499462197300167, 0.2018001937719968, 0.19731779227591595, 0.1954100313205122, 0.18942741368501, 0.18253075331013463, 0.18025086571119484]]]\n"
     ]
    }
   ],
   "source": [
    "filtered_index = filter_dog(data,[0,1],[3],[0])\n",
    "dont_like_index = [3,5,6] #These are indexes for dogs that the user don't like\n",
    "filtered_index_remove_dontlike = filter_dont_like(nofilter, dont_like_index)\n",
    "# No filter means all the dogs are picked. No need to do the filter for age gender and HDB.\n",
    "# filtered_index = filter_dont_like(filtered)\n",
    "# print(filtered_index)\n",
    "history_index = [0,20,42,25] #These are indexes for dogs that the user like\n",
    "recommend_dogs = recommend_userhistory(data,nofilter,history_index,10)\n",
    "print(recommend_dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History Preference Dogs:\n",
      " absolute darling food take medicine food aggression starve point confident trust independent separation anxiety company story able smiley face\n",
      " stunning little settle training socialisation\n",
      " shy sweet quiet sweet affectionate super shy face guess stop share good guidance support eat play walk sleep trust smart bad\n",
      " giant affection excitement welcome happily enter enclosure walk leash outside spook vehicle panic hard size strong able walk sweet oversized affection attention\n",
      "Recommended Dogs:\n",
      " quiet super sweet little shy good food motivate walk leash\n",
      " shy reserved smart special enjoy quiet nervous confidence take walk outside leash stop walk sweet kind play good hassle\n",
      " little shy quiet calm walk leash\n",
      " quiet shy sweet gorgeous affectionate kind share son company gentle confident cuddle enjoy walk outdoor adventure walk leash pace calm support senior\n",
      " cute little puppy aggression settle little fearful insecure pant sweet little underneath stick comfort sit enclosure trust\n",
      " shy warm food motivated peepad aggression walk leash long settle\n",
      " long long starve lock backyard starve food starve attention thrive attention interact lock away food waste food eat morsel walk affectionate walk lead sit wait food serve jump food sweet sweet wait\n",
      " shy hesitant trust affection\n",
      " sweet gentle temperament walk leash little shy warm\n",
      " sweet puppy bond previous take great change happen maybe trigger anxiety guarding ferociously outdoors boisterous friendly difficult spot uncomfortable display sign anxiety afraid food environmental control anxiety guard great companion food motivated game fetch enjoy long walk friendly excitement sniff initiate play independent challenge perfect training proper able settle comfortably take consistency anxiety guard idea willing walk child\n"
     ]
    }
   ],
   "source": [
    "print('History Preference Dogs:')\n",
    "for index in history_index:\n",
    "    print(data.loc[index]['Corpus'])\n",
    "    \n",
    "print('Recommended Dogs:')\n",
    "for index in recommend_dogs[0][0]:\n",
    "    print(data.loc[index]['Corpus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXQlTlVC_NjE"
   },
   "source": [
    "## **Recommender for new users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1770"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_user_description(description, corpus_words):\n",
    "    des = ''\n",
    "    sentence = my_preprocessing(description)\n",
    "#     print(sentence)\n",
    "    for word in sentence:\n",
    "        if word in corpus_words:\n",
    "            des += ' '\n",
    "            des += word\n",
    "#     print(des)\n",
    "    return des\n",
    "\n",
    "def new_user_tfidf_list(des,corpus):\n",
    "    corpus_new = []\n",
    "    corpus_new.append(des)\n",
    "    for text in corpus:\n",
    "        corpus_new.append(text)\n",
    "#     print(len(corpus_new))\n",
    "    vectorizer = CountVectorizer()\n",
    "    word_vec = vectorizer.fit_transform(corpus_new)\n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf = transformer.fit_transform(word_vec)\n",
    "    tfidf_matrix = tfidf.toarray()\n",
    "#     print(tfidf_matrix.shape)\n",
    "    return tfidf_matrix[0]\n",
    "    \n",
    "des = process_user_description('feh ge cute fe afe',corpus_words)\n",
    "len(new_user_tfidf_list(des,corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_new_user(description,tags,corpus,corpus_words):\n",
    "    user = []\n",
    "    user.append(666)\n",
    "    user.append('NewUser')\n",
    "    user.append(0)\n",
    "    user.append(0)\n",
    "    user.append(0)\n",
    "    des = process_user_description(description, corpus_words)\n",
    "#     print(des)\n",
    "    user.append(des)\n",
    "    for i in tags:\n",
    "        user.append(i)\n",
    "    for i in new_user_tfidf_list(des,corpus):\n",
    "        user.append(i)\n",
    "    return user\n",
    "\n",
    "# data.loc[666] = build_new_user('cute lovely shy quiet',[1,1,1,1,1,1],corpus,corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_newuser(data,gender,age,hdb,description,tags,corpus,corpus_words,target_num,filter_hard):\n",
    "#     print(description)\n",
    "#     print(tags)\n",
    "    data.loc[666] = build_new_user(description,tags,corpus,corpus_words)\n",
    "    if filter_hard == True:\n",
    "        filtered_index = filter_dog(data,gender,age,hdb)\n",
    "    else:\n",
    "        filtered_index = filter_dog(data,[0,1],[0,1,2,3],[0,1])\n",
    "    similarity = []\n",
    "    print('Dogs after filtering:' + str(filtered_index))\n",
    "    for index in filtered_index:\n",
    "        cos_sim = cosine_similarity(data.loc[index],data.loc[666],hard_constraint=False,soft_constraint=True,tfidf=True,user=True)\n",
    "        similarity.append(cos_sim)\n",
    "    for i in range(len(similarity)):\n",
    "        print('similarity for index ' + str(filtered_index[i])+ ' : ' +str(similarity[i]))\n",
    "    max_index_ = list(map(similarity.index, heapq.nlargest(target_num,similarity)))\n",
    "    max_index = []\n",
    "    num = min(target_num,len(filtered_index))\n",
    "    for i in range(len(max_index_)):\n",
    "        max_index.append(filtered_index[max_index_[i]])\n",
    "    max_value = heapq.nlargest(num,similarity)\n",
    "#     print(len(max_index))\n",
    "#     max_value = [0,0,0,0,0] #try all 0\n",
    "    return_null = 1\n",
    "    for i in range(num):\n",
    "        if max_value[i] != 0:\n",
    "            return_null = 0\n",
    "    if return_null == 1:\n",
    "        return []\n",
    "    for i in range(num):\n",
    "        if max_value[num-i-1] == 0:\n",
    "#             print(len(max_index)-i-1)\n",
    "            max_index.pop(num-i-1)\n",
    "            max_value.pop(num-i-1)\n",
    "    return max_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogs after filtering:[24, 45, 97, 108, 138, 144, 161, 171, 177, 182, 190, 192, 195, 217, 227, 260, 280, 285, 320]\n",
      "similarity for index 24 : 0\n",
      "similarity for index 45 : 0\n",
      "similarity for index 97 : 0\n",
      "similarity for index 108 : 0\n",
      "similarity for index 138 : 0\n",
      "similarity for index 144 : 0\n",
      "similarity for index 161 : 0\n",
      "similarity for index 171 : 0\n",
      "similarity for index 177 : 0\n",
      "similarity for index 182 : 0\n",
      "similarity for index 190 : 0\n",
      "similarity for index 192 : 0\n",
      "similarity for index 195 : 0\n",
      "similarity for index 217 : 0\n",
      "similarity for index 227 : 0\n",
      "similarity for index 260 : 0\n",
      "similarity for index 280 : 0\n",
      "similarity for index 285 : 0\n",
      "similarity for index 320 : 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "max_index = recommend_newuser(data,[1],[2],[1],'ute',[1,1,1,1,1,1],corpus,corpus_words,5,filter_hard=True)\n",
    "# print()\n",
    "print(max_index)\n",
    "# print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogs Recommended:\n",
      " cute small walk leash\n",
      "[0, 0, 0, 0, 0, 0]\n",
      " shy warm affectionate ask quiet walk rub\n",
      "[0, 0, 0, 0, 0, 0]\n",
      " quiet super sweet little shy good food motivate walk leash\n",
      "[0, 0, 0, 0, 0, 0]\n",
      " shy sweet quiet sweet affectionate super shy face guess stop share good guidance support eat play walk sleep trust smart bad\n",
      "[0, 0, 0, 0, 0, 0]\n",
      " development stage suffice cute smart presence puppy young term good\n",
      "[0, 0, 0, 0, 0, 1]\n",
      " good shy indoor avs catcher petrify take warm quiet gentle calm nature leash walk willing indoor walk leash\n",
      "[0, 0, 0, 0, 0, 1]\n",
      " loyal friendly nervous surrender lovely loyal anxious surrender allegedly bite suggest bit possessive child behaviour walk behaviour result frightened loud happen outside patient resettle\n",
      "[0, 0, 0, 0, 1, 0]\n",
      " confident dare explore afraid photo angel cute choose mean peace safety italian lord enable save\n",
      "[0, 0, 0, 0, 0, 1]\n",
      " shy warm food motivated peepad aggression walk leash long settle\n",
      "[0, 0, 0, 0, 0, 0]\n",
      " approx outram long terrified pup walk confidently leash scritche play crazy sis run shy take warm pup pup gentle sniff situation quickly nervous energy nervous shy away aggressive good adult child sible speed play chill snooze away overall behave sweet quick learner rough mama blind slow hbd patient dedication structure lovely\n",
      "[1, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print('Dogs Recommended:')\n",
    "for index in max_index[0]:\n",
    "    print(data.loc[index]['Corpus'])\n",
    "    tags = []\n",
    "    for i in range(6):\n",
    "        tags.append(data.loc[index]['Tag'+str(i+3)])\n",
    "    print(tags)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py38gpu",
   "language": "python",
   "name": "py38gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
