{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmSfXw1huDPP"
   },
   "source": [
    "## **Import Libraries**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wMjmX8aOtykL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import csv\n",
    "import math\n",
    "import heapq\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woTSmIewa2HY"
   },
   "source": [
    "## **Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NS1VJCAKt6Il",
    "outputId": "561bd5ee-5dc8-49be-9f7c-dc31ee0b2a54"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('newdata_2.csv')\n",
    "# print(tfidf['Name'])\n",
    "# print(data)\n",
    "# print(data.shape)\n",
    "\n",
    "corpus = list(data['Corpus'])\n",
    "# print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAbhkYpIEtbq"
   },
   "source": [
    "## **Build Up the Language Processor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mYfkXLM9E3K6"
   },
   "outputs": [],
   "source": [
    "def my_preprocessing(raw_sentence):\n",
    "    nlp_tool = spacy.load('en_core_web_sm')\n",
    "    token_sentence = nlp_tool(raw_sentence.lower())\n",
    "    with open('./irrelevant_words.txt') as file:\n",
    "        irrelevantlist = [stopword.replace('\\n', '').lower() for stopword in file.readlines()]\n",
    "#     new_sentence = [word for word in token_sentence if word not in irrelevantlist]\n",
    "    \n",
    "    preprocessed_sentence = []\n",
    "    \n",
    "    for token in token_sentence:\n",
    "        if token.pos_ == \"PUNCT\" or token.is_stop == True or token.is_alpha == False or token.pos_ == \"SYM\":\n",
    "            continue\n",
    "\n",
    "        elif token.lemma_ in irrelevantlist or len(token)==1:\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            preprocessed_sentence.append(token.lemma_)\n",
    "            \n",
    "    return preprocessed_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JRjfY4ZbAWT"
   },
   "source": [
    "## Basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dogs after filterring: 11\n",
      "Index of dogs after filtering:\n",
      "[110, 160, 178, 179, 181, 205, 219, 233, 275, 296, 297]\n"
     ]
    }
   ],
   "source": [
    "# Filter the dogs according to the hard constraints (gender, age and HDB approval)\n",
    "def filter_dog(data,gender,age,hdb):\n",
    "    filtered = []\n",
    "    for i in range(335):\n",
    "        if data.loc[i,'Gender'] in gender:\n",
    "            if data.loc[i,'Age'] in age:\n",
    "                if data.loc[i,'HDB'] in hdb:\n",
    "                    filtered.append(i)\n",
    "    return filtered\n",
    "\n",
    "# Test\n",
    "filtered = filter_dog(data,[1],[2],[0])\n",
    "print('Number of dogs after filterring: ' + str(len(filtered)))\n",
    "print('Index of dogs after filtering:')\n",
    "print(filtered)\n",
    "# index = []\n",
    "# for dog in filtered:\n",
    "#     index.append(dog['Index'])\n",
    "# print(index)\n",
    "\n",
    "nofilter = filter_dog(data,[0,1],[0,1,2,3],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m dogs_value_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m335\u001b[39m):\n\u001b[1;32m---> 19\u001b[0m     dogs_value_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmake_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mmake_list\u001b[1;34m(dog_index, hard_constraints, tfidf, soft_constraints)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tfidf \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1770\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m         value_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdog_index\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m soft_constraints \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m):\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\py38gpu\\lib\\site-packages\\pandas\\core\\indexing.py:1074\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1071\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1073\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\py38gpu\\lib\\site-packages\\pandas\\core\\indexing.py:1313\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\py38gpu\\lib\\site-packages\\pandas\\core\\indexing.py:1261\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   1260\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\py38gpu\\lib\\site-packages\\pandas\\core\\generic.py:4077\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4072\u001b[0m         \u001b[38;5;66;03m# if we encounter an array-like and we only have 1 dim\u001b[39;00m\n\u001b[0;32m   4073\u001b[0m         \u001b[38;5;66;03m# that means that their are list/ndarrays inside the Series!\u001b[39;00m\n\u001b[0;32m   4074\u001b[0m         \u001b[38;5;66;03m# so just return them (GH 6394)\u001b[39;00m\n\u001b[0;32m   4075\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n\u001b[1;32m-> 4077\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4079\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(\n\u001b[0;32m   4080\u001b[0m         new_mgr, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex[loc]\n\u001b[0;32m   4081\u001b[0m     )\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   4082\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(loc):\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\py38gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1099\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m   1094\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_empty((n,), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;66;03m# error: Argument \"dtype\" to \"empty\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# \"Union[Type[object], dtype[Any], ExtensionDtype, None]\"; expected\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;66;03m# \"None\"\u001b[39;00m\n\u001b[1;32m-> 1099\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimmutable_ea\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1102\u001b[0m     result \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(result)\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;66;03m# Such assignment may incorrectly coerce NaT to None\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;66;03m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Make a list of values of dogs to calculate cosine similarity\n",
    "def make_list(dog_index,hard_constraints,tfidf,soft_constraints):\n",
    "    value_list = []\n",
    "    if hard_constraints == True: \n",
    "        value_list.append(data.loc[dog_index]['Gender'])\n",
    "        value_list.append(data.loc[dog_index]['Age'])\n",
    "        value_list.append(data.loc[dog_index]['HDB'])\n",
    "    if tfidf == True:\n",
    "        for i in range(1770):\n",
    "            value_list.append(data.loc[dog_index]['tfidf'+str(i)])\n",
    "    if soft_constraints == True:\n",
    "        for i in range(6):\n",
    "            value_list.append(data.loc[dog_index]['Tag'+str(i+3)])\n",
    "#     print(len(value_list))\n",
    "    return value_list\n",
    "\n",
    "dogs_value_list = []\n",
    "for i in range(335):\n",
    "    dogs_value_list.append(make_list(i,True,True,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9925833339709303"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculation of the cosine similarity given two lists of vlaues\n",
    "def cosine_similarity(listx,listy):\n",
    "    numerator = 0\n",
    "    denominator_x = 0\n",
    "    denominator_y = 0\n",
    "#     if len(listx) != len(listy):\n",
    "#         raise Exception('The two input lists of the cosine similarity calculator are not in the same length!')\n",
    "#     if hard_constraint == True:\n",
    "#         numerator += data.loc[indexx]['Gender']\n",
    "    for i in range(len(listx)):\n",
    "        numerator += listx[i] * listy[i]\n",
    "        denominator_x += listx[i]**2\n",
    "        denominator_y += listy[i]**2\n",
    "    denominator_x = math.sqrt(denominator_x)\n",
    "    denominator_y = math.sqrt(denominator_y)  \n",
    "    return (numerator/(denominator_x*denominator_y))\n",
    "\n",
    "# Test\n",
    "# print(cosine_similarity(make_list(data.loc[0]),make_list(data.loc[70])))\n",
    "cosine_similarity([2,3,4],[2,4,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of cosine similarity between two dogs\n",
    "# For the soft constraints, if the value of one certain aspect for either dog is 0, it won't be taken into calculation.\n",
    "def cossim_dog_dog(dogx_index,dogy_index):\n",
    "    listx = make_list(dogx_index,hard_constraints=True,tfidf=True,soft_constraints=True)\n",
    "    listy = make_list(dogy_index,hard_constraints=True,tfidf=True,soft_constraints=True)\n",
    "    for i in range(1773,1779):\n",
    "        if listx[i] == 0 or listy[i] == 0:\n",
    "            listx[i] = 0\n",
    "            listy[i] = 0\n",
    "    cossim = cosine_similarity(listx,listy)\n",
    "    return cossim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of cosine similarity between one dog and the user's profile\n",
    "# Used in recommendation for a new user\n",
    "# The hard constraints are filtered before the calcularion, thus not taken into account\n",
    "# For the soft constraints, if the value of one certain aspect for the dog is 0, \n",
    "# or that of the user's profile is 1, it won't be taken into calculation.\n",
    "def cossim_dog_userprofile(user,dog_index):\n",
    "    listx = make_list(user,False,True,True)\n",
    "    listy = make_list(dog,False,True,True)\n",
    "    for i in range(1773-3,1779-3):\n",
    "        if listx[i] == 1 or listy[i] == 0:\n",
    "            listx[i] = 0\n",
    "            listy[i] = 0\n",
    "    cossim = cosine_similarity(listx,listy)\n",
    "    return cossim\n",
    "\n",
    "# Test\n",
    "# cossim_dog_dog(data.loc[0],data.loc[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of cosine similarity between one dog and the user's history selection\n",
    "# Used in recommendation for an old user after he/she has selected some dogs\n",
    "# Only consider the descriptions of the dogs\n",
    "def cossim_dog_userhistory(history,dog_index):\n",
    "#     listy = make_list(dog_index,hard_constraints=False,tfidf=True,soft_constraints=False,data)\n",
    "    listy = make_list(dog_index,False,True,False)\n",
    "    cossim = cosine_similarity(history,listy)\n",
    "    return cossim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>HDB</th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "      <th>Tag6</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf1760</th>\n",
       "      <th>tfidf1761</th>\n",
       "      <th>tfidf1762</th>\n",
       "      <th>tfidf1763</th>\n",
       "      <th>tfidf1764</th>\n",
       "      <th>tfidf1765</th>\n",
       "      <th>tfidf1766</th>\n",
       "      <th>tfidf1767</th>\n",
       "      <th>tfidf1768</th>\n",
       "      <th>tfidf1769</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Adora</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>absolute darling food take medicine food aggr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Adore Blessing</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>tip tiny bit smart unfamiliar pretend calm fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ah Boy</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>sweet absolutely companion hesitate affection...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ah Leng</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>anxious afraid affection trust wriggle seek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>recall post baby display change temperament b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>331</td>\n",
       "      <td>Vicki</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>low energy adorable sweetheart chew furniture...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>332</td>\n",
       "      <td>Watson</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>wander gleefully carry crate different bite p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>333</td>\n",
       "      <td>Wiley</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>affectionate excitable hyper fearful tuggish ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>334</td>\n",
       "      <td>Zane</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>handsome bad aggression deep crave puppy driv...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>999</td>\n",
       "      <td>History</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>courpus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 1782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Index            Name  Gender  Age  HDB  \\\n",
       "0        0           Adora       0    3    1   \n",
       "1        1  Adore Blessing       0    3    1   \n",
       "2        2          Ah Boy       1    3    0   \n",
       "3        3         Ah Leng       0    3    0   \n",
       "4        4          Alaska       1    3    0   \n",
       "..     ...             ...     ...  ...  ...   \n",
       "331    331           Vicki       0    3    0   \n",
       "332    332          Watson       1    3    1   \n",
       "333    333           Wiley       1    3    0   \n",
       "334    334            Zane       1    3    0   \n",
       "335    999         History       0    0    0   \n",
       "\n",
       "                                                Corpus  Tag3  Tag4  Tag5  \\\n",
       "0     absolute darling food take medicine food aggr...     0     0     0   \n",
       "1     tip tiny bit smart unfamiliar pretend calm fi...     0     0     0   \n",
       "2     sweet absolutely companion hesitate affection...     0     0     1   \n",
       "3          anxious afraid affection trust wriggle seek     0     0     0   \n",
       "4     recall post baby display change temperament b...     1     1     0   \n",
       "..                                                 ...   ...   ...   ...   \n",
       "331   low energy adorable sweetheart chew furniture...     0     0     0   \n",
       "332   wander gleefully carry crate different bite p...     0     0     0   \n",
       "333   affectionate excitable hyper fearful tuggish ...     0     0     0   \n",
       "334   handsome bad aggression deep crave puppy driv...     0     0     0   \n",
       "335                                            courpus     0     0     0   \n",
       "\n",
       "     Tag6  ...  tfidf1760  tfidf1761  tfidf1762  tfidf1763  tfidf1764  \\\n",
       "0       1  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "1       0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "2       0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "3       1  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "4       1  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "..    ...  ...        ...        ...        ...        ...        ...   \n",
       "331     0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "332     0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "333     0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "334     0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "335     0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "     tfidf1765  tfidf1766  tfidf1767  tfidf1768  tfidf1769  \n",
       "0          0.0        0.0        0.0        0.0        0.0  \n",
       "1          0.0        0.0        0.0        0.0        0.0  \n",
       "2          0.0        0.0        0.0        0.0        0.0  \n",
       "3          0.0        0.0        0.0        0.0        0.0  \n",
       "4          0.0        0.0        0.0        0.0        0.0  \n",
       "..         ...        ...        ...        ...        ...  \n",
       "331        0.0        0.0        0.0        0.0        0.0  \n",
       "332        0.0        0.0        0.0        0.0        0.0  \n",
       "333        0.0        0.0        0.0        0.0        0.0  \n",
       "334        0.0        0.0        0.0        0.0        0.0  \n",
       "335        0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[336 rows x 1782 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Based on user's history data, build a user's prefernce.\n",
    "# Only consider the tfidf\n",
    "def user_history(dogs_index):\n",
    "    history = []\n",
    "    history.append(999)\n",
    "    history.append('History')\n",
    "    history.append(0)\n",
    "    history.append(0)\n",
    "    history.append(0)\n",
    "    history.append('courpus')\n",
    "    for i in range(6):\n",
    "        history.append(0)\n",
    "    for i in range(1770):\n",
    "        summ = 0\n",
    "        average = 0\n",
    "        for index in dogs_index:\n",
    "            summ += data.loc[index]['tfidf'+str(i)]\n",
    "        average = summ/len(dogs_index)\n",
    "        history.append(average)\n",
    "#     data.loc[335] = history\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender for old users based on the user's history prefernece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the similar dogs according to cosine similarity\n",
    "def recommend_userhistory(dogs_filter_index,history_index,target_num):\n",
    "    similarity = []\n",
    "    history = user_history(history_index)\n",
    "#     print(len(history))\n",
    "    num = 1\n",
    "    for index in dogs_filter_index:\n",
    "        cos_sim = cossim_dog_userhistory(history,index)\n",
    "        print(str(num) + '/' + str(len(dogs_filter_index)) + ' : ' + str(cos_sim))\n",
    "        similarity.append(cos_sim)\n",
    "        num += 1\n",
    "#     print(similarity)\n",
    "    max_index_ = list(map(similarity.index, heapq.nlargest(target_num,similarity)))\n",
    "    max_index = []\n",
    "    for i in range(len(max_index_)):\n",
    "        max_index.append(dogs_filter_index[max_index_[i]])\n",
    "    max_value = heapq.nlargest(target_num,similarity)\n",
    "    return [[max_index],[max_value]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/335 : 0.5273493333322952\n",
      "2/335 : 0.02349846609718914\n",
      "3/335 : 0.14396210159463668\n",
      "4/335 : 0.10900206350340742\n",
      "5/335 : 0.05229946239031541\n",
      "6/335 : 0.10718501103979583\n",
      "7/335 : 0.06679619231839563\n",
      "8/335 : 0.06580937181830881\n",
      "9/335 : 0.011807634328146476\n",
      "10/335 : 0.04005512091193892\n",
      "11/335 : 0.0\n",
      "12/335 : 0.056824401172797495\n",
      "13/335 : 0.17268415543140814\n",
      "14/335 : 0.08312462133693337\n",
      "15/335 : 0.06911183112637968\n",
      "16/335 : 0.08731604662277424\n",
      "17/335 : 0.06353440733884716\n",
      "18/335 : 0.01475314018192458\n",
      "19/335 : 0.06697547130806672\n",
      "20/335 : 0.1150197117999076\n",
      "21/335 : 0.48418817050636465\n",
      "22/335 : 0.03418436478626665\n",
      "23/335 : 0.07322404297391855\n",
      "24/335 : 0.020954147433664312\n",
      "25/335 : 0.03732223605520729\n",
      "26/335 : 0.5180140458040923\n",
      "27/335 : 0.07282935831839055\n",
      "28/335 : 0.01938373470928547\n",
      "29/335 : 0.15294005021534832\n",
      "30/335 : 0.08612786457493765\n",
      "31/335 : 0.07308474391656578\n",
      "32/335 : 0.10780590817106742\n",
      "33/335 : 0.011912637925654371\n",
      "34/335 : 0.09749775620943132\n",
      "35/335 : 0.12795530076274902\n",
      "36/335 : 0.0\n",
      "37/335 : 0.051323754733686285\n",
      "38/335 : 0.10216761370185695\n",
      "39/335 : 0.05495708063205548\n",
      "40/335 : 0.22443746451740343\n",
      "41/335 : 0.14374000895790318\n",
      "42/335 : 0.009062507322727427\n",
      "43/335 : 0.5357611971134686\n",
      "44/335 : 0.04120022364445508\n",
      "45/335 : 0.10174728946945\n",
      "46/335 : 0.054479475006819336\n",
      "47/335 : 0.03668907604757387\n",
      "48/335 : 0.12053909056327437\n",
      "49/335 : 0.0\n",
      "50/335 : 0.11871656116561856\n",
      "51/335 : 0.055187902799975784\n",
      "52/335 : 0.11081411983430507\n",
      "53/335 : 0.07129344681165878\n",
      "54/335 : 0.09398505388233058\n",
      "55/335 : 0.1126159369032951\n",
      "56/335 : 0.05309298162278532\n",
      "57/335 : 0.06381818259490728\n",
      "58/335 : 0.0401299261212518\n",
      "59/335 : 0.01078676996375493\n",
      "60/335 : 0.0\n",
      "61/335 : 0.08510357473035864\n",
      "62/335 : 0.026664432396647057\n",
      "63/335 : 0.08553355561217811\n",
      "64/335 : 0.06747334949987557\n",
      "65/335 : 0.010225062213344582\n",
      "66/335 : 0.1954100313205122\n",
      "67/335 : 0.03928566896667543\n",
      "68/335 : 0.008931374567027427"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [127]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# print(filtered_index)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m history_index \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m42\u001b[39m,\u001b[38;5;241m25\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m recommend_dogs \u001b[38;5;241m=\u001b[39m \u001b[43mrecommend_userhistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnofilter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhistory_index\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(recommend_dogs)\n",
      "Input \u001b[1;32mIn [115]\u001b[0m, in \u001b[0;36mrecommend_userhistory\u001b[1;34m(dogs_filter_index, history_index, target_num)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m dogs_filter_index:\n\u001b[0;32m      8\u001b[0m     cos_sim \u001b[38;5;241m=\u001b[39m cossim_dog_userhistory(history,index)\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdogs_filter_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m : \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcos_sim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     similarity\u001b[38;5;241m.\u001b[39mappend(cos_sim)\n\u001b[0;32m     11\u001b[0m     num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\py38gpu\\lib\\site-packages\\ipykernel\\iostream.py:555\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 555\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\py38gpu\\lib\\site-packages\\ipykernel\\iostream.py:461\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_schedule_in_thread\u001b[39m():\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39mcall_later(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_interval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[1;32m--> 461\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_schedule_in_thread\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\py38gpu\\lib\\site-packages\\ipykernel\\iostream.py:210\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     f()\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\py38gpu\\lib\\site-packages\\zmq\\sugar\\socket.py:618\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    611\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[0;32m    612\u001b[0m             data,\n\u001b[0;32m    613\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[0;32m    614\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    615\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[0;32m    616\u001b[0m         )\n\u001b[0;32m    617\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m--> 618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:740\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:787\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:244\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\py38gpu\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filtered_index = filter_dog([0,1],[3],[0])\n",
    "# print(filtered_index)\n",
    "history_index = [0,20,42,25]\n",
    "recommend_dogs = recommend_userhistory(nofilter,history_index,5)\n",
    "print(recommend_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXQlTlVC_NjE"
   },
   "source": [
    "## **Recommender for new users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrLBbCh1_3yp",
    "outputId": "edb12179-7904-4125-b6d0-eeb3715348a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "['vjhgycfuyfytf']\n",
      "72\n",
      "['vjhgycfuyfytf ', ' absolute darling food take medicine food aggression starve point confident trust independent separation anxiety company story able smiley face', ' tip tiny bit smart unfamiliar pretend calm fine cool pup mesmerize pup puppy inside', ' eat handfeed meal eat fearful take trust cheer confidence', ' ash young mum hard gentle nurture soul shine quiet thoughtful smooch happily trick caring compassionate confidence understand bit shy ideal child pet perfect companion quiet friendly pet good manner ash pup bail pound save euthanize petite size perfect ash great compassion shy young mum proud irresistibly adorable pup nervous doggie timid nature encounter warm low maintenance gentle opportunity explore perfect companion furry chill petite size sharp feature narrow bridge large pointy ash shiny beauty throw curveball shyness noticed easily forget long special true affectionate beauty lie beauty lie', ' long aggressive threaten attack fear change enjoy walk enjoy affection company good toddler small young child', ' submissive shy crave companion peek patiently wait food shy timid bad warm cut solitary figure parking commercial compound ang mo kio dart everyday gardener office staff witness deliver pup conscientious hide pup harm ensure hungry throw food eat challenge food danger pup run difficult baby chase escape gentle little warm', ' break survive heal mend walk learning trust low maintenance easily contend frequent walk sweet sensitive attention diamond rose blossom ordinary extraordinary pal', ' cuddly curious little cautious joy bravely finish heartworm ready beauty cuddle attention little curious outside loud patient work confidence walk couch snuggle', ' loyal friendly nervous surrender lovely loyal anxious surrender allegedly bite suggest bit possessive child behaviour walk behaviour result frightened loud happen outside patient resettle', ' crush death machinery mild natured perfect kid', ' sociable friendly relaxed sweet independent lose captain naturally little lose good enjoy explore stretch relaxed perfect companion curl couch captain truly offer', ' shy sweet quiet sweet affectionate super shy face guess stop share good guidance support eat play walk sleep trust smart bad', ' bubbly young worker big size spaniel play fetch long run stroll work enjoy company young mind little cheeky appreciate firm good little scar damage destroy true beauty guess small pretty enchant', ' jurong island caregiver loving interactive take warm cataract little insecure gotten line sweet willing past insecurity warm', ' handicap low spine cripple waist crawl chest drag painfully rough gravel spot jurong island hard food swallow gravel pin alleviate gnaw hunger hard baby fate change mr kind muslim work attention changed clearly enjoy lease unfortunate episode threaten away chest infection haze blockage brave valiantly admirably warrior condition wobbly unable control poo acupuncture hydrotherapy able walk normally bundle joy good fortune sweet natured fun playful puppy proper deserve', ' approx outram long terrified pup walk confidently leash scritche play crazy sis run shy take warm pup pup gentle sniff situation quickly nervous energy nervous shy away aggressive good adult child sible speed play chill snooze away overall behave sweet quick learner rough mama blind slow hbd patient dedication structure lovely', ' beauty face beauty cut kind thick thin pregnancy fire warm lose process destination embark lifetime fun fact alfa', ' sweet shy nervous lifetime horrifying condition chain cage entire save chain action comfortable indoor outdoors expect sweet walk harness leash patient world scary deserve', ' good shy indoor avs catcher petrify take warm quiet gentle calm nature leash walk willing indoor walk leash', ' quiet timid kind gentle dame sweet friendly enjoy outside senior outdoors pleasure walk trot alongside patiently take stop lose good dandy pass away originally trap golden wait long', ' recent batch jurong island shy warm rub kangaroo leash kangaroo lead afraid leash', ' comfortable easily win', ' shy excellent comfortable walk leash', ' mini sized mongrel super cute face nice shade friendly wag welcome walk leash moment expect confidence quickly quickly petite size sweet careful install window grill agile climb scale er enclosure fence', ' attention loiter trap neuter release feedback run road matter gets sterilization spay fearful clinic cage surprisingly arrive appear fairly relaxed wag show sign aggression leash matter important wander', ' quiet shy sweet gorgeous affectionate kind share son company gentle confident cuddle enjoy walk outdoor adventure walk leash pace calm support senior', ' confident dare explore afraid photo angel cute choose mean peace safety italian lord enable save', ' wonderful walking partner tv experienced dedicated single fear hide good kid kid walk outdoor gentle cuddle good swim roll mud play charming doggie selective adapt walk healthy outdoor', ' beautiful young energy active playful great outdoors', ' affectionate charm gaze smooth wavy lock raise safe take walk terrify rainy display fear aggression apartment living send work trust safe company foreign', ' gentle chill good warm friendly face gentle calm good ride confidence easily walk patient young kid', ' wander aimlessly toa payoh save authority loom lasso ready capture kind scoop hesitation run irresponsible dirty bite bug cause problem cite oh disease bite bug cure world alright shall nap imply total sweet', ' hide weak emaciate quickly medley infect blotchy urinate urinary tract infection uti barely ray suggest moment poorly hospital regain strength discharge course complete uti bright pass able face tale sign tough hard remain sweet gentle proper hopeful good consider deserve keen senior write', ' mean good good pup calm gentle settle smile wide pass wagging tough pup yound safe run scavage food', ' frightened anxious smart young spend nervous anxious spend encourage terrified wear harness walk confidently outside experienced patiently encourage trust loud frightened tolerant', ' passionate active enjoy outside walk run rough wrestling constantly ask affection enjoy good belly rub roll ask strong leash good experienced active lifestyle', ' charming sweet friendly move cheerful resilient living beautiful stop visitor track', ' shy disposition trust confident companion assurance venture break fuss free walk good roll', ' friendly affectionate company', ' shy warm food motivated peepad aggression walk leash long settle', ' shy break gentle enjoy tender blossom wonderful companion', ' quiet low maintainance food motivated affectionate matured active walk small cosy temperament fact easy walk timer consider unit friendly', ' shy hesitant trust affection', ' quiet super sweet little shy good food motivate walk leash', ' gentle mild mannered independent enjoy lounge walk leash calm walk enjoy greenery prefer walk pace', ' cute small walk leash', ' result intentional hill coordinate round hill pup hiding pup hour mean strength not impressive photo cow spot shade adorable gorgeous shy gentle warm easily', ' reflect foxy pierce beautiful small curly bushy calm walk little shy newly', ' sweet food motivate walk leash sociable', ' trailer lose scatter hide tiny gap tyre slow tiny run safety arise trailer move matter particular trailer move crush brim affectionate playful inquisitive teachable', ' term overly friendly face enthusiastically jump hate dependent type character walk leash listen scold business walk', ' fish emaciate small food water provide deny say fish food gobble immediately ask away agree fearful social till protective food starve long', ' sweet small sized badly matted condition mild gentle shave arrival inside gum possible tie nature bind waist abuse homeless case', ' existence miraculous happening capture limp disappear long reappear emaciate die survive limp completely restore abnormality walk', ' pretty fast food drink sweet making', ' noami timid settle walk play abit wear physically obviously smooth scar special scar good curious meaningful tug noami', ' sweet harsh veterinarian suspect blind puppy plague sickness survive overcome sickness repair blind cause pain discomfort limited vision average smart survive fake newspaper cover cleanly splendid puppy enable healthily', ' play young popular fun tolerant shy face hide little bit sensitve gentle rough', ' quiet independent gentle shy aggression observe timid lovely shy little mth baby adapt world work display sign aggression blossom tender', ' aggression good unfamiliar face walk leash spend explore curiously walk leash surrounding slowly', ' sign aggression sweet natured training boarding share condition boarding good living condition furry baby provide typically high survival instinct escape artist alertness leash leash training break leash escape show aggression sweet temperament confident excel', ' friendly carefree able run fishfarm change caregiver unwilling intention sterilize chew hole cage run gotten injure seek round calm content safe', ' comfortable presence avoid squirm away interact warm realize harm', ' sweet warm fairly quickly warm affectionate enjoy neck scratch food motivate', ' exuberant little enthused walk', ' sterilize trap puppy authority complaint meek afraid heartworm concurrently warm heartworm', ' roam suspect pad anxious small willingly crate seek refuge great low energy enjoy take slow walk little hard hearing raise voice slowly hang sense dull cataract pretty sharp food forage food food remain rubbish spite rough healthy work weak severely malnourish walk wag hop meal walk keen senior permanent', ' shy take observe quietly slowly okay meal hopefully opportunity comfortable', ' real cutie pie warm whine excitedly walk leash outside confidence take blossom brave loving', ' free spirited enjoy freedom complaint smart careful bond teach walk leash chew leash worried lose', ' stuck swamp alert kind sight spot howl trouble scavenge food assume wit safety quickly obvious discomfort pain snarl aggressively sweet pain cope able prop enjoy walk review schedule good recovery comfortable']\n"
     ]
    }
   ],
   "source": [
    "def filter(gender,age,hdb):\n",
    "  filtered = []\n",
    "  for i in range(335):\n",
    "    if data.loc[i,'Gender'] in gender:\n",
    "      if data.loc[i,'Age'] in age:\n",
    "        if data.loc[i,'HDB'] in hdb:\n",
    "          filtered.append(data.loc[i])\n",
    "  return filtered\n",
    "\n",
    "# dog_filter = filter([0],[1,3],[1])\n",
    "# print(len(dog_filter))\n",
    "# # print(dog_filter[3])\n",
    "\n",
    "# user_dog_des = 'I want a vjhgycfuyfytf.'\n",
    "# user_dog_des = my_preprocessing(user_dog_des)\n",
    "# print(user_dog_des)\n",
    "# user_dog_des_str = ''\n",
    "# for word in user_dog_des:\n",
    "#   user_dog_des_str += word\n",
    "#   user_dog_des_str += ' '\n",
    "# corpus_new = []\n",
    "# corpus_new.append(user_dog_des_str)\n",
    "# for dog in dog_filter:\n",
    "#   corpus_new.append(dog['Corpus'])\n",
    "# print(len(corpus_new))\n",
    "# # print(len(corpus))\n",
    "# print(corpus_new)\n",
    "def generateNewCorpus(dog_filter, dog_description):\n",
    "  print(len(dog_filter))\n",
    "  # print(dog_filter[3])\n",
    "\n",
    "  user_dog_des = my_preprocessing(dog_description)\n",
    "  print(user_dog_des)\n",
    "  user_dog_des_str = ''\n",
    "  for word in user_dog_des:\n",
    "    user_dog_des_str += word\n",
    "    user_dog_des_str += ' '\n",
    "  corpus_new = []\n",
    "  corpus_new.append(user_dog_des_str)\n",
    "  for dog in dog_filter:\n",
    "    corpus_new.append(dog['Corpus'])\n",
    "  print(len(corpus_new))\n",
    "  # print(len(corpus))\n",
    "  print(corpus_new)\n",
    "  return corpus_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D869f3bkA0PC",
    "outputId": "c57a267b-470c-47f2-87b0-c66a8cdbaecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 714)\n",
      "[0, 0, 0, 0, 0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      " absolute darling food take medicine food aggression starve point confident trust independent separation anxiety company story able smiley face\n",
      " absolute darling food take medicine food aggression starve point confident trust independent separation anxiety company story able smiley face\n",
      " absolute darling food take medicine food aggression starve point confident trust independent separation anxiety company story able smiley face\n",
      " absolute darling food take medicine food aggression starve point confident trust independent separation anxiety company story able smiley face\n",
      " absolute darling food take medicine food aggression starve point confident trust independent separation anxiety company story able smiley face\n"
     ]
    }
   ],
   "source": [
    "# vectorizer = CountVectorizer()\n",
    "# word_vec = vectorizer.fit_transform(corpus_new)\n",
    "# # print(word_vec.toarray())\n",
    "# # print(vectorizer.get_feature_names())\n",
    "# transformer = TfidfTransformer()\n",
    "# tfidf = transformer.fit_transform(word_vec)\n",
    "# tfidf_matrix = tfidf.toarray()\n",
    "# print(tfidf_matrix.shape)\n",
    "# # print(tfidf_matrix)\n",
    "# # print(tfidf_matrix[71][1])\n",
    "# cosim = []\n",
    "# denominator_user = 0\n",
    "# for j in range(tfidf_matrix.shape[1]):\n",
    "#   denominator_user += tfidf_matrix[0][j]**2\n",
    "# denominator_user = math.sqrt(denominator_user)\n",
    "# for i in range(1,tfidf_matrix.shape[0]):\n",
    "#   numerator = 0\n",
    "#   denominator_target = 0\n",
    "#   for j in range(tfidf_matrix.shape[1]):\n",
    "#     numerator += tfidf_matrix[0][j]*tfidf_matrix[i][j]\n",
    "#     denominator_target += tfidf_matrix[i][j]**2\n",
    "#   denominator_target = math.sqrt(denominator_target)\n",
    "#   cosim.append(numerator/(denominator_user*denominator_target))\n",
    "\n",
    "# target_num = 5\n",
    "# max_index = list(map(cosim.index, heapq.nlargest(target_num,cosim)))\n",
    "# max_value = heapq.nlargest(target_num,cosim)\n",
    "# print(max_index)\n",
    "# print(max_value)\n",
    "\n",
    "# for index in max_index:\n",
    "#   print(dog_filter[index]['Corpus'])\n",
    "\n",
    "def getTargetDogs(dog_description):  \n",
    "  dog_filter = filter([0],[1,3],[1])\n",
    "  vectorizer = CountVectorizer()\n",
    "  corpus_new = generateNewCorpus(dog_filter, dog_description)\n",
    "  word_vec = vectorizer.fit_transform(corpus_new)\n",
    "  # print(word_vec.toarray())\n",
    "  # print(vectorizer.get_feature_names())\n",
    "  transformer = TfidfTransformer()\n",
    "  tfidf = transformer.fit_transform(word_vec)\n",
    "  tfidf_matrix = tfidf.toarray()\n",
    "  print(tfidf_matrix.shape)\n",
    "  # print(tfidf_matrix)\n",
    "  # print(tfidf_matrix[71][1])\n",
    "  cosim = []\n",
    "  denominator_user = 0\n",
    "  for j in range(tfidf_matrix.shape[1]):\n",
    "    denominator_user += tfidf_matrix[0][j]**2\n",
    "  denominator_user = math.sqrt(denominator_user)\n",
    "  for i in range(1,tfidf_matrix.shape[0]):\n",
    "    numerator = 0\n",
    "    denominator_target = 0\n",
    "    for j in range(tfidf_matrix.shape[1]):\n",
    "      numerator += tfidf_matrix[0][j]*tfidf_matrix[i][j]\n",
    "      denominator_target += tfidf_matrix[i][j]**2\n",
    "    denominator_target = math.sqrt(denominator_target)\n",
    "    cosim.append(numerator/(denominator_user*denominator_target))\n",
    "\n",
    "  target_num = 5\n",
    "  max_index = list(map(cosim.index, heapq.nlargest(target_num,cosim)))\n",
    "  max_value = heapq.nlargest(target_num,cosim)\n",
    "  print(max_index)\n",
    "  print(max_value)\n",
    "\n",
    "  for index in max_index:\n",
    "    print(dog_filter[index]['Corpus'])\n",
    "  return max_index\n",
    "\n",
    "dog_description = \"I like a smart dog\"\n",
    "target = getTargetDogs(dog_description)\n",
    "print('target:', target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtjUCnJPV1rr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xch-2RqmXNBk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py38gpu",
   "language": "python",
   "name": "py38gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
